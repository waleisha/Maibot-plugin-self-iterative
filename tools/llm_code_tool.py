"""
LLMä»£ç ç”Ÿæˆå·¥å…· - ä½¿ç”¨ç‹¬ç«‹LLMæ¨¡å‹ç”Ÿæˆä»£ç ä¿®æ”¹

è¿™ä¸ªå·¥å…·å…è®¸AIç›´æ¥è°ƒç”¨é…ç½®çš„ç‹¬ç«‹LLMæ¨¡å‹æ¥ç”Ÿæˆä»£ç ä¿®æ”¹ï¼Œ
è€Œä¸éœ€è¦AIè‡ªå·±ç”Ÿæˆä¿®æ”¹åçš„ä»£ç ã€‚
"""

import os
from pathlib import Path
from typing import Dict, Any, List, Tuple
from src.plugin_system import BaseTool, ToolParamType
from src.common.logger import get_logger

from ..core.llm_client import get_llm_client

logger = get_logger("self_iterative_plugin.tools.llm_code")


class LLMCodeGenerateTool(BaseTool):
    """
    LLMä»£ç ç”Ÿæˆå·¥å…·
    
    ä½¿ç”¨é…ç½®çš„ç‹¬ç«‹LLMæ¨¡å‹ï¼ˆClaudeã€Geminiã€Kimiç­‰ï¼‰æ¥ç”Ÿæˆä»£ç ä¿®æ”¹ã€‚
    è¿™ä¸ªå·¥å…·è®©AIå¯ä»¥è°ƒç”¨æ›´å¼ºå¤§çš„æ¨¡å‹æ¥ç”Ÿæˆé«˜è´¨é‡çš„ä»£ç ã€‚
    
    ä½¿ç”¨åœºæ™¯:
    - å¤æ‚çš„ä»£ç é‡æ„
    - Bugä¿®å¤
    - åŠŸèƒ½æ·»åŠ 
    - ä»£ç ä¼˜åŒ–
    """
    
    name = "llm_generate_code"
    description = """ä½¿ç”¨ç‹¬ç«‹LLMæ¨¡å‹ç”Ÿæˆä»£ç ä¿®æ”¹ã€‚å½“ä½ éœ€è¦ä¿®æ”¹ä»£ç ä½†ä¸ç¡®å®šå¦‚ä½•ä¿®æ”¹æ—¶ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·è®©ä¸“ä¸šçš„ä»£ç æ¨¡å‹æ¥ç”Ÿæˆä¿®æ”¹ã€‚

ä½¿ç”¨åœºæ™¯:
- å¤æ‚çš„ä»£ç é‡æ„
- Bugä¿®å¤
- æ·»åŠ æ–°åŠŸèƒ½
- ä»£ç ä¼˜åŒ–

æ³¨æ„: è¿™ä¸ªå·¥å…·ä¼šè°ƒç”¨é…ç½®çš„ç‹¬ç«‹LLMæ¨¡å‹ï¼ˆå¦‚Claudeã€Geminiç­‰ï¼‰ï¼Œå¯èƒ½éœ€è¦é¢å¤–çš„APIè°ƒç”¨æ—¶é—´ã€‚"""
    
    available_for_llm = True
    
    parameters = [
        ("file_path", ToolParamType.STRING, "è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºMaiBotæ ¹ç›®å½•ï¼‰", True, None),
        ("task_description", ToolParamType.STRING, "ä¿®æ”¹ä»»åŠ¡æè¿°ï¼Œä¾‹å¦‚ï¼šä¼˜åŒ–æ—¥å¿—è¾“å‡ºã€ä¿®å¤ç¬¬50è¡Œçš„bugç­‰", True, None),
        ("offset", ToolParamType.INTEGER, "èµ·å§‹è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œé»˜è®¤è¯»å–æ•´ä¸ªæ–‡ä»¶", False, 1),
        ("limit", ToolParamType.INTEGER, "æœ€å¤šè¯»å–è¡Œæ•°ï¼Œé»˜è®¤è¯»å–500è¡Œ", False, 500),
    ]
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.plugin_dir = Path(__file__).parent.parent
        self.mai_bot_root = self._find_maibot_root()
        self._llm_client = None
    
    def _find_maibot_root(self) -> Path:
        """æŸ¥æ‰¾MaiBotæ ¹ç›®å½•"""
        current = self.plugin_dir
        while current.parent != current:
            if (current / "bot.py").exists() or (current / "main.py").exists():
                return current
            current = current.parent
        return self.plugin_dir.parent.parent
    
    def _get_llm_client(self):
        """è·å–LLMå®¢æˆ·ç«¯"""
        if self._llm_client is None:
            # æ„å»ºé…ç½®å­—å…¸
            config = {
                "plugin": {"enabled": True},
                "llm": {
                    "provider": self.get_config("llm.provider", "default"),
                    "temperature": self.get_config("llm.temperature", 0.3),
                    "max_tokens": self.get_config("llm.max_tokens", 4096),
                    "openai": {
                        "model": self.get_config("llm.openai.model", "gpt-4o"),
                        "api_key": self.get_config("llm.openai.api_key", ""),
                        "base_url": self.get_config("llm.openai.base_url", "https://api.openai.com/v1"),
                    },
                    "anthropic": {
                        "model": self.get_config("llm.anthropic.model", "claude-3-5-sonnet-20241022"),
                        "api_key": self.get_config("llm.anthropic.api_key", ""),
                        "base_url": self.get_config("llm.anthropic.base_url", "https://api.anthropic.com/v1"),
                    },
                    "google": {
                        "model": self.get_config("llm.google.model", "gemini-2.0-flash-exp"),
                        "api_key": self.get_config("llm.google.api_key", ""),
                    },
                    "moonshot": {
                        "model": self.get_config("llm.moonshot.model", "kimi-latest"),
                        "api_key": self.get_config("llm.moonshot.api_key", ""),
                        "base_url": self.get_config("llm.moonshot.base_url", "https://api.moonshot.cn/v1"),
                    },
                    "deepseek": {
                        "model": self.get_config("llm.deepseek.model", "deepseek-coder"),
                        "api_key": self.get_config("llm.deepseek.api_key", ""),
                        "base_url": self.get_config("llm.deepseek.base_url", "https://api.deepseek.com/v1"),
                    },
                },
            }
            self._llm_client = get_llm_client(config)
        return self._llm_client
    
    def _get_allowed_read_paths(self) -> List[Path]:
        """è·å–å…è®¸çš„è¯»å–è·¯å¾„åˆ—è¡¨"""
        allowed = self.get_config("security.allowed_read_paths", [
            "src",
            "plugins",
            "maibot_plugin_self_iterative"
        ])
        paths = []
        for path_str in allowed:
            if os.path.isabs(path_str):
                paths.append(Path(path_str))
            else:
                paths.append(self.mai_bot_root / path_str)
        return paths
    
    def _is_path_allowed(self, target_path: Path) -> Tuple[bool, str]:
        """æ£€æŸ¥ç›®æ ‡è·¯å¾„æ˜¯å¦å…è®¸è¯»å–"""
        abs_target = self.mai_bot_root / target_path
        abs_target = abs_target.resolve()
        
        allowed_paths = self._get_allowed_read_paths()
        in_whitelist = any(
            self._is_subpath(abs_target, allowed)
            for allowed in allowed_paths
        )
        if not in_whitelist:
            return False, f"ç›®æ ‡è·¯å¾„ä¸åœ¨å…è®¸çš„ç™½åå•å†…: {target_path}"
        
        forbidden_patterns = self.get_config("security.forbidden_patterns", [
            ".*\\.env.*", ".*token.*", ".*password.*", ".*secret.*",
            ".*credential.*", ".*api_key.*", ".*private.*"
        ])
        
        import re
        target_str = str(abs_target).lower()
        for pattern in forbidden_patterns:
            try:
                if re.match(pattern, target_str, re.IGNORECASE):
                    return False, f"ç›®æ ‡è·¯å¾„åŒ¹é…ç¦æ­¢æ¨¡å¼: {pattern}"
            except re.error:
                continue
        
        return True, ""
    
    def _is_subpath(self, path: Path, potential_parent: Path) -> bool:
        """æ£€æŸ¥pathæ˜¯å¦æ˜¯potential_parentçš„å­è·¯å¾„"""
        try:
            path.relative_to(potential_parent)
            return True
        except ValueError:
            return False
    
    async def execute(self, function_args: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç ç”Ÿæˆ"""
        file_path_str = function_args.get("file_path", "")
        task_description = function_args.get("task_description", "")
        offset = function_args.get("offset", 1)
        limit = function_args.get("limit", 500)
        
        try:
            # å®‰å…¨æ£€æŸ¥
            is_allowed, error_msg = self._is_path_allowed(Path(file_path_str))
            if not is_allowed:
                logger.warning(f"[LLMCodeGenerateTool] æ‹’ç»è¯»å–: {error_msg}")
                return {
                    "name": self.name,
                    "content": f"âŒ è¯»å–è¢«æ‹’ç»: {error_msg}",
                    "success": False
                }
            
            # è¯»å–æ–‡ä»¶
            file_path = self.mai_bot_root / file_path_str
            if not file_path.exists():
                return {
                    "name": self.name,
                    "content": f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path_str}",
                    "success": False
                }
            
            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                lines = f.readlines()
            
            total_lines = len(lines)
            start_idx = max(0, offset - 1)
            end_idx = min(total_lines, start_idx + limit)
            selected_lines = lines[start_idx:end_idx]
            code = ''.join(selected_lines)
            
            logger.info(f"[LLMCodeGenerateTool] è¯»å–æ–‡ä»¶: {file_path_str} ({total_lines}è¡Œ)")
            
            # ä½¿ç”¨LLMç”Ÿæˆä¿®æ”¹
            llm_client = self._get_llm_client()
            
            provider = self.get_config("llm.provider", "default")
            logger.info(f"[LLMCodeGenerateTool] ä½¿ç”¨LLMæ¨¡å‹: {provider}")
            
            success, new_code = await llm_client.analyze_code(
                file_path=file_path_str,
                code=code,
                task_description=task_description
            )
            
            if not success:
                return {
                    "name": self.name,
                    "content": f"âŒ ä»£ç ç”Ÿæˆå¤±è´¥: {new_code}",
                    "success": False
                }
            
            # ç”Ÿæˆä¿®æ”¹æè¿°
            description = await llm_client.generate_diff_description(code, new_code)
            
            logger.info(f"[LLMCodeGenerateTool] ä»£ç ç”ŸæˆæˆåŠŸ")
            
            return {
                "name": self.name,
                "content": f"âœ… **ä»£ç ç”ŸæˆæˆåŠŸ**\n\nğŸ“ **ä¿®æ”¹æè¿°**: {description}\n\nğŸ“ **åŸä»£ç **: {len(code)} å­—ç¬¦\nğŸ“ **æ–°ä»£ç **: {len(new_code)} å­—ç¬¦\n\nğŸ’¡ **ä¸‹ä¸€æ­¥**: ä½ å¯ä»¥ä½¿ç”¨ `self_iterate` å·¥å…·æäº¤è¿™ä¸ªä¿®æ”¹:\n```json\n{{\n  \"target_path\": \"{file_path_str}\",\n  \"modification_description\": \"{description}\",\n  \"new_content\": \"...ç”Ÿæˆçš„ä»£ç ...\"\n}}\n```",
                "success": True,
                "target_path": file_path_str,
                "modification_description": description,
                "new_content": new_code,
                "original_length": len(code),
                "new_length": len(new_code)
            }
            
        except Exception as e:
            error_msg = f"ä»£ç ç”Ÿæˆæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(f"[LLMCodeGenerateTool] {error_msg}")
            return {
                "name": self.name,
                "content": f"âŒ {error_msg}",
                "success": False
            }
